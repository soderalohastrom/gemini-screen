<!DOCTYPE html>
<html data-theme="light">

<head>
    <title>Screen Buddy</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>

    <style>
        /* Theme Variables */
        :root[data-theme="light"] {
            --bg-primary: #f0f2f5;
            --bg-secondary: #ffffff;
            --text-primary: #2c3e50;
            --text-secondary: #34495e;
            --accent-primary: #3498db;
            --accent-secondary: #2980b9;
            --shadow-color: rgba(0, 0, 0, 0.1);
            --inset-shadow: inset 2px 2px 5px var(--shadow-color);
            --outset-shadow:
                -5px -5px 10px rgba(255, 255, 255, 0.8),
                5px 5px 10px var(--shadow-color);
            --button-hover: rgba(52, 152, 219, 0.1);
        }

        :root[data-theme="dark"] {
            --bg-primary: #1a1a1a;
            --bg-secondary: #2d2d2d;
            --text-primary: #ecf0f1;
            --text-secondary: #bdc3c7;
            --accent-primary: #3498db;
            --accent-secondary: #2980b9;
            --shadow-color: rgba(0, 0, 0, 0.3);
            --inset-shadow: inset 2px 2px 5px var(--shadow-color);
            --outset-shadow:
                -5px -5px 10px rgba(255, 255, 255, 0.05),
                5px 5px 10px var(--shadow-color);
            --button-hover: rgba(52, 152, 219, 0.2);
        }

        /* Reset & Base Styles */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: all 0.3s ease;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            min-height: 100vh;
        }

        /* Video and Canvas */
        #videoElement {
            width: 1000px;
            height: 750px;
            border-radius: 20px;
            display: block;
            margin: 0 auto;
        }

        #canvasElement {
            display: none;
            width: 1000px;
            height: 750px;
        }

        /* Layout and Controls */
        .header {
            padding: 1rem 2rem;
            background: var(--bg-secondary);
            box-shadow: var(--outset-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            transition: transform 0.3s ease;
        }

        .header-group {
            display: flex;
            align-items: center;
            gap: 3rem;
            margin: 0 auto;
        }

        .header.collapsed {
            transform: translateY(-100%);
        }

        .app-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: var(--text-primary);
            text-shadow: 1px 1px 2px var(--shadow-color);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .app-title .material-icons {
            font-size: 1.8rem;
            color: var(--accent-primary);
        }

        .main-content {
            padding: 2rem;
            max-width: 1100px;
            margin: 0 auto;
            margin-top: 60px; /* Match header height */
            transition: margin-top 0.3s ease;
        }

        .main-content.header-collapsed {
            margin-top: 0;
        }

        .video-portal {
            position: relative;
            width: 100%;
            background: var(--bg-secondary);
            border-radius: 20px;
            padding: 1rem;
            box-shadow: var(--outset-shadow);
            margin-bottom: 2rem;
        }

        .video-container {
            position: relative;
            width: 100%;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: var(--inset-shadow);
            display: flex;
            justify-content: center;
        }

        .controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 1rem;
            position: relative;
            bottom: 0.5rem;
        }

        .control-button {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: none;
            background: var(--bg-secondary);
            color: var(--text-primary);
            cursor: pointer;
            box-shadow: var(--outset-shadow);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s ease;
        }

        .control-button:hover {
            background: var(--button-hover);
        }

        .control-button:active {
            box-shadow: var(--inset-shadow);
        }

        .control-button.active {
            background: var(--accent-primary);
            color: white;
        }

        /* Chat Log */
        #chatLog {
            margin-top: 2rem;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 15px;
            box-shadow: var(--inset-shadow);
            max-height: 300px;
            overflow-y: auto;
        }

        #chatLog p {
            margin: 0.5rem 0;
            padding: 0.8rem;
            border-radius: 8px;
            background: var(--bg-secondary);
            box-shadow: var(--outset-shadow);
            color: var(--text-primary);
            font-size: 1.1rem;
            line-height: 1.5;
        }

        #chatLog p.gemini {
            border-left: 4px solid var(--accent-primary);
        }

        /* Theme Toggle */
        .theme-toggle {
            padding: 0.5rem;
            border-radius: 50%;
            border: none;
            background: var(--bg-secondary);
            color: var(--text-primary);
            cursor: pointer;
            box-shadow: var(--outset-shadow);
        }

        .theme-toggle:active {
            box-shadow: var(--inset-shadow);
        }

        /* Custom Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-primary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--accent-primary);
            border-radius: 4px;
        }
    </style>
</head>

<body>
    <header class="header">
        <div class="header-group">
            <button id="screenShareButton" class="control-button">
                <i class="material-icons">screen_share</i>
            </button>
            <h1 class="app-title">Screen Buddy</h1>
            <button id="themeToggle" class="theme-toggle" onclick="toggleTheme()">
                <span class="material-icons">dark_mode</span>
            </button>
        </div>
    </header>

    <main class="main-content">
        <div class="video-portal">
            <div class="video-container">
                <video id="videoElement" autoplay></video>
                <canvas id="canvasElement"></canvas>
            </div>
            <div class="controls">
                <button id="micButton" class="control-button">
                    <i class="material-icons">mic</i>
                </button>
            </div>
        </div>
        <div id="chatLog"></div>
    </main>

    <script defer>
        // Theme toggle functionality
        function toggleTheme() {
            const html = document.documentElement;
            const themeToggle = document.getElementById('themeToggle');
            const currentTheme = html.getAttribute('data-theme');
            const newTheme = currentTheme === 'light' ? 'dark' : 'light';
            const icon = themeToggle.querySelector('.material-icons');

            html.setAttribute('data-theme', newTheme);
            icon.textContent = newTheme === 'light' ? 'dark_mode' : 'light_mode';
        }

        // Check user's preferred color scheme
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            document.documentElement.setAttribute('data-theme', 'dark');
        }

        // Listen for system theme changes
        window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {
            document.documentElement.setAttribute('data-theme', event.matches ? 'dark' : 'light');
        });

        // Audio context and stream management
        let audioContext = null;
        let audioStream = null;
        let workletInitialized = false;
        let audioQualityMonitor = {
            lastCheckTime: 0,
            sampleCount: 0,
            clippingCount: 0,
            underrunCount: 0,
            overrunCount: 0
        };

        // Initialize AudioContext with proper sample rate handling
        async function initAudioContext(preferredSampleRate = 16000) {
            try {
                if (!audioContext) {
                    // Try to match device capabilities
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const audioDevice = devices.find(device => device.kind === 'audioinput');

                    if (audioDevice) {
                        const constraints = {
                            audio: {
                                deviceId: audioDevice.deviceId,
                                sampleRate: {
                                    ideal: preferredSampleRate
                                }
                            }
                        };

                        // Test device capabilities
                        const testStream = await navigator.mediaDevices.getUserMedia(constraints);
                        const track = testStream.getAudioTracks()[0];
                        const capabilities = track.getCapabilities();
                        testStream.getTracks().forEach(track => track.stop());

                        // Use supported sample rate
                        const sampleRate = capabilities.sampleRate?.max >= preferredSampleRate ?
                            preferredSampleRate : capabilities.sampleRate?.max || 44100;

                        console.log(`Using sample rate: ${sampleRate}Hz`);

                        audioContext = new (window.AudioContext || window.webkitAudioContext)({
                            sampleRate: sampleRate,
                            latencyHint: 'interactive'
                        });

                        await initializeAudioWorklet();
                    } else {
                        throw new Error('No audio input device found');
                    }
                }

                if (audioContext.state === "suspended") {
                    await audioContext.resume();
                }

                return audioContext;
            } catch (error) {
                console.error('Error initializing audio context:', error);
                throw error;
            }
        }

        // Monitor audio quality
        function updateAudioQualityMetrics(audioData) {
            const now = performance.now();
            if (now - audioQualityMonitor.lastCheckTime > 1000) {
                const metrics = {
                    timestamp: new Date().toISOString(),
                    clippingRatio: audioQualityMonitor.clippingCount / audioQualityMonitor.sampleCount,
                    underrunCount: audioQualityMonitor.underrunCount,
                    overrunCount: audioQualityMonitor.overrunCount
                };

                console.log('Audio Quality Metrics:', metrics);

                // Reset counters
                audioQualityMonitor.lastCheckTime = now;
                audioQualityMonitor.sampleCount = 0;
                audioQualityMonitor.clippingCount = 0;
                audioQualityMonitor.underrunCount = 0;
                audioQualityMonitor.overrunCount = 0;
            }

            // Update metrics
            audioQualityMonitor.sampleCount += audioData.length;
            audioData.forEach(sample => {
                if (Math.abs(sample) > 0.95) {
                    audioQualityMonitor.clippingCount++;
                }
            });
        }

        const URL = `wss://${window.location.hostname}/ws`;
        const video = document.getElementById("videoElement");
        const canvas = document.getElementById("canvasElement");
        const header = document.querySelector('.header');
        let context;
        let webSocket = null;
        let isWebSocketReady = false;
        let isHeaderVisible = true;

        // Header show/hide logic
        let mouseY = 0;
        const headerHeight = 60;
        const showHeaderThreshold = 30;

        document.addEventListener('mousemove', (e) => {
            mouseY = e.clientY;
            if (mouseY <= showHeaderThreshold) {
                header.classList.remove('collapsed');
                document.querySelector('.main-content').classList.remove('header-collapsed');
                isHeaderVisible = true;
            } else if (mouseY > headerHeight && stream) {
                header.classList.add('collapsed');
                document.querySelector('.main-content').classList.add('header-collapsed');
                isHeaderVisible = false;
            }
        });

        function collapseHeader() {
            if (isHeaderVisible) {
                header.classList.add('collapsed');
                document.querySelector('.main-content').classList.add('header-collapsed');
                isHeaderVisible = false;
            }
        }

        // Initialize context here
        window.addEventListener("load", async () => {
            context = canvas.getContext("2d");
            await connect();
            setInterval(captureImage, 3000);
        });

        const micButton = document.getElementById('micButton');
        let isMicActive = false;
        let stream = null;
        let currentFrameB64;
        let mediaRecorder = null;
        let audioWorkletNode = null;
        let inputWorkletNode = null;
        let interval = null;
        let initialized = false;

        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.length; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        function base64ToArrayBuffer(base64) {
            const binary_string = atob(base64);
            const len = binary_string.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binary_string.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Function to start screen capture
        async function startScreenShare() {
            try {
                if (!stream) {
                    stream = await navigator.mediaDevices.getDisplayMedia({
                        video: {
                            width: {
                                max: 800
                            },
                            height: {
                                max: 600
                            },
                        },
                    });

                    video.srcObject = stream;
                    await new Promise(resolve => {
                        video.onloadedmetadata = () => {
                            console.log("video loaded metadata");
                            resolve();
                        }
                    });

                    // Handle stream end
                    stream.getVideoTracks()[0].onended = () => {
                        stream = null;
                        video.srcObject = null;
                    };

                    // Collapse header after screen is shared
                    collapseHeader();
                }
            } catch (err) {
                console.error("Error accessing the screen: ", err);
            }
        }

        // Function to capture an image from the shared screen
        function captureImage() {
            if (stream && video.videoWidth > 0 && video.videoHeight > 0 && context) {
                canvas.width = 640;
                canvas.height = 480;
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                const imageData = canvas.toDataURL("image/jpeg").split(",")[1].trim();
                currentFrameB64 = imageData;
            } else {
                console.log("no stream or video metadata not loaded");
            }
        }

        // Add screen share button handler
        document.getElementById('screenShareButton').addEventListener('click', async () => {
            await startScreenShare();
        });

        function connect() {
            return new Promise((resolve, reject) => {
                console.log("Attempting WebSocket connection to:", URL);

                if (webSocket && webSocket.readyState !== WebSocket.CLOSED) {
                    console.log("Closing existing WebSocket connection");
                    webSocket.close();
                }

                try {
                    console.log("Creating new WebSocket instance");
                    webSocket = new WebSocket(URL);

                    webSocket.onclose = (event) => {
                        console.log("WebSocket closed with code:", event.code);
                        console.log("Close reason:", event.reason);
                        isWebSocketReady = false;
                        console.log("Scheduling reconnection attempt in 1 second");
                        setTimeout(() => connect(), 1000);
                    };

                    webSocket.onerror = (event) => {
                        console.error("WebSocket error:", event);
                        console.error("WebSocket state:", webSocket.readyState);
                        isWebSocketReady = false;
                    };

                    webSocket.onopen = async (event) => {
                        console.log("WebSocket connection established");
                        isWebSocketReady = true;
                        // Send setup message immediately after setting ready state
                        try {
                            await sendInitialSetupMessage();
                            console.log("Setup message sent successfully");
                        } catch (error) {
                            console.error("Error sending setup message:", error);
                            console.error("Error details:", error.message);
                            console.error("Error stack:", error.stack);
                        }
                        resolve();
                    };

                    webSocket.onmessage = receiveMessage;
                } catch (error) {
                    console.error("Error creating WebSocket:", error);
                    console.error("Error details:", error.message);
                    console.error("Error stack:", error.stack);
                    reject(error);
                }
            });
        }

        async function sendInitialSetupMessage() {
            if (!isWebSocketReady) {
                console.log("WebSocket not ready for setup message");
                return;
            }

            console.log("Preparing setup message");
            const setup_client_message = {
                setup: {
                    generation_config: {
                        response_modalities: ["AUDIO", "TEXT"]
                    },
                },
            };

            console.log('Setup message details:', JSON.stringify(setup_client_message, null, 2));
            
            try {
                await new Promise((resolve, reject) => {
                    webSocket.send(JSON.stringify(setup_client_message));
                    console.log('Setup message sent successfully');
                    resolve();
                });
            } catch (error) {
                console.error('Error sending setup message:', error);
                throw error;
            }
        }

        function sendVoiceMessage(b64PCM) {
            if (!isWebSocketReady) {
                console.log("websocket not ready");
                return;
            }

            const payload = {
                realtime_input: {
                    media_chunks: [{
                            mime_type: "audio/pcm",
                            data: b64PCM,
                        },
                        {
                            mime_type: "image/jpeg",
                            data: currentFrameB64,
                        },
                    ],
                },
            };

            webSocket.send(JSON.stringify(payload));
            console.log("sent voice message");
        }

        function receiveMessage(event) {
            try {
                console.log('Received WebSocket message:', event);
                const messageData = JSON.parse(event.data);
                console.log('Raw message data:', messageData);
                
                const response = new Response(messageData);
                console.log('Parsed response:', {
                    hasText: !!response.text,
                    hasAudio: !!response.audioData,
                    text: response.text,
                    audioLength: response.audioData ? response.audioData.length : 0
                });

                if (response.text) {
                    console.log('Displaying text message:', response.text);
                    displayMessage("GEMINI: " + response.text);
                }
                if (response.audioData) {
                    console.log('Processing audio chunk of length:', response.audioData.length);
                    ingestAudioChunkToPlay(response.audioData);
                }
            } catch (error) {
                console.error('Error processing message:', error);
                console.error('Error stack:', error.stack);
            }
        }

        class Response {
            constructor(data) {
                this.text = null;
                this.audioData = null;
                this.endOfTurn = null;

                if (data && typeof data === 'object') {
                    if ('text' in data) {
                        this.text = data.text;
                        console.log('Received text:', data.text);
                    }

                    if ('audio' in data) {
                        this.audioData = data.audio;
                        console.log('Received audio data of length:', data.audio.length);
                    }

                    console.log('Full response data:', JSON.stringify(data, null, 2));
                } else {
                    console.warn('Invalid response data:', data);
                }
            }
        }


        async function initializeAudioWorklet() {
            if (workletInitialized) {
                console.log('Audio worklet already initialized');
                return;
            }

            try {
                console.log('Loading pcm-processor.js module');
                await audioContext.audioWorklet.addModule("pcm-processor.js");
                console.log('PCM processor module loaded successfully');

                // Create output worklet node
                console.log('Creating output worklet node');
                audioWorkletNode = new AudioWorkletNode(audioContext, "pcm-processor", {
                    processorOptions: {
                        mode: 'output'
                    }
                });
                audioWorkletNode.port.onmessage = (e) => {
                    console.log('Output worklet message:', e.data);
                };
                audioWorkletNode.connect(audioContext.destination);
                console.log('Output worklet connected to destination');

                // Create input worklet node
                console.log('Creating input worklet node');
                inputWorkletNode = new AudioWorkletNode(audioContext, "pcm-processor", {
                    processorOptions: {
                        mode: 'input'
                    }
                });
                inputWorkletNode.port.onmessage = (e) => {
                    if (e.data.type === 'audio_data') {
                        console.log('Received audio data from input worklet');
                        const base64 = arrayBufferToBase64(e.data.buffer);
                        sendVoiceMessage(base64);
                    } else {
                        console.log('Received non-audio message from input worklet:', e.data);
                    }
                };

                initialized = true;
                workletInitialized = true;
                console.log("Audio worklet system fully initialized");
            } catch (error) {
                console.error("Failed to initialize audio worklet:", error);
                console.error("Error details:", error.message);
                console.error("Error stack:", error.stack);
                workletInitialized = false;
                initialized = false;
                throw error;  // Re-throw to handle in the calling function
            }
        }

        function convertPCM16LEToFloat32(pcmData) {
            const inputArray = new Int16Array(pcmData);
            const float32Array = new Float32Array(inputArray.length);

            for (let i = 0; i < inputArray.length; i++) {
                float32Array[i] = inputArray[i] / 32768;
            }

            return float32Array;
        }

        async function ingestAudioChunkToPlay(base64AudioChunk) {
            try {
                console.log('Processing audio chunk, length:', base64AudioChunk.length);
                
                if (!audioContext) {
                    throw new Error('Audio context not initialized');
                }
                
                if (audioContext.state === "suspended") {
                    console.log('Resuming suspended audio context');
                    await audioContext.resume();
                }
                console.log('Audio context state:', audioContext.state);
                
                if (!audioWorkletNode) {
                    throw new Error('Audio worklet not initialized');
                }
                
                const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
                console.log('Converted to array buffer, size:', arrayBuffer.byteLength);
                
                const float32Data = convertPCM16LEToFloat32(arrayBuffer);
                console.log('Converted to float32, samples:', float32Data.length);
                console.log('Sample values range:', {
                    min: Math.min(...float32Data),
                    max: Math.max(...float32Data)
                });

                audioWorkletNode.port.postMessage(float32Data);
                console.log('Audio data sent to worklet');
            } catch (error) {
                console.error("Error processing audio chunk:", error);
                console.error("Error details:", error.message);
                console.error("Error stack:", error.stack);
                console.error("Audio context state:", audioContext?.state);
                console.error("Worklet initialized:", !!audioWorkletNode);
            }
        }

        async function startAudioInput() {
            try {
                // Initialize audio context with device-compatible sample rate
                await initAudioContext();

                // Close any existing audio stream
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }

                // Get supported constraints
                const deviceCapabilities = await navigator.mediaDevices.getSupportedConstraints();
                const audioConstraints = {
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                };

                // Add sample rate if supported
                if (deviceCapabilities.sampleRate) {
                    audioConstraints.sampleRate = {
                        ideal: audioContext.sampleRate
                    };
                }

                // Get new audio stream
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: audioConstraints
                });

                // Create and configure audio source
                const source = audioContext.createMediaStreamSource(audioStream);

                // Add gain node for volume control
                const gainNode = audioContext.createGain();
                gainNode.gain.value = 1.0; // Adjustable gain
                source.connect(gainNode);
                gainNode.connect(inputWorkletNode);

                // Inform worklet about actual sample rate
                const streamSettings = audioStream.getAudioTracks()[0].getSettings();
                inputWorkletNode.port.postMessage({
                    type: 'set_sample_rate',
                    sampleRate: streamSettings.sampleRate
                });

                // Set up buffer processing with dynamic interval
                const bufferInterval = Math.floor(1000 * (2048 / audioContext.sampleRate));
                interval = setInterval(() => {
                    if (inputWorkletNode?.port) {
                        inputWorkletNode.port.postMessage({
                            type: 'get_buffer'
                        });
                    }
                }, bufferInterval);

                // Add audio quality monitoring
                const analyzerNode = audioContext.createAnalyser();
                analyzerNode.fftSize = 2048;
                source.connect(analyzerNode);

                const monitorInterval = setInterval(() => {
                    const dataArray = new Float32Array(analyzerNode.frequencyBinCount);
                    analyzerNode.getFloatTimeDomainData(dataArray);
                    updateAudioQualityMetrics(dataArray);
                }, 1000);

                console.log(`Audio input started successfully:
                    Sample Rate: ${streamSettings.sampleRate}Hz
                    Buffer Interval: ${bufferInterval}ms
                    Monitoring: Active`);

            } catch (error) {
                console.error("Error starting audio input:", error);
                displayMessage("Error: Could not start audio input. Please check your microphone settings.");
                throw error;
            }
        }

        function stopAudioInput() {
            if (inputWorkletNode) {
                inputWorkletNode.disconnect();
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            clearInterval(interval);
            interval = null;
            console.log("Audio input stopped");
        }

        function displayMessage(message) {
            console.log('Displaying message:', message);
            try {
                addParagraphToDiv("chatLog", message);
                console.log('Message added to chat log successfully');
            } catch (error) {
                console.error('Error displaying message:', error);
            }
        }

        function addParagraphToDiv(divId, text) {
            console.log('Adding paragraph to div:', { divId, text });
            try {
                const newParagraph = document.createElement("p");
                newParagraph.textContent = text;
                if (text.startsWith("GEMINI:")) {
                    console.log('Adding Gemini styling');
                    newParagraph.classList.add("gemini");
                    // Remove the "GEMINI:" prefix for cleaner display
                    newParagraph.textContent = text.substring(7).trim();
                }
                const div = document.getElementById(divId);
                if (!div) {
                    throw new Error(`Chat log div not found: ${divId}`);
                }
                div.appendChild(newParagraph);
                // Auto-scroll to bottom
                div.scrollTop = div.scrollHeight;
                console.log('Paragraph added and scrolled to bottom');
            } catch (error) {
                console.error('Error adding paragraph:', error);
                throw error;
            }
        }

        // Add click handlers with user gesture handling
        micButton.addEventListener('click', async () => {
            try {
                if (isMicActive) {
                    stopAudioInput();
                    micButton.querySelector('i').textContent = 'mic';
                    micButton.classList.remove('active');
                } else {
                    await startAudioInput();
                    micButton.querySelector('i').textContent = 'mic_off';
                    micButton.classList.add('active');
                }
                isMicActive = !isMicActive;
            } catch (error) {
                console.error("Error toggling audio:", error);
            }
        });
    </script>

</body>

</html>
